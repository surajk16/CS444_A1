{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Colab Setup\n",
    "If you aren't using Colab, you can delete the following code cell. This is just to help students with mounting to Google Drive to access the other .py files and downloading the data, which is a little trickier on Colab than on your local machine using Jupyter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will be prompted with a window asking to grant permissions\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n",
    "import os\n",
    "datadir = \"/content/assignment1\"\n",
    "if not os.path.exists(datadir):\n",
    "  !ln -s \"/content/drive/My Drive/YOUR PATH HERE/assignment1/\" $datadir\n",
    "os.chdir(datadir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading Fashion-MNIST\n",
    "import os\n",
    "os.chdir(os.path.join(datadir,\"fashion-mnist/\"))\n",
    "!chmod +x ./get_data.sh\n",
    "!./get_data.sh\n",
    "os.chdir(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_FASHION_data, get_RICE_data\n",
    "from scipy.spatial import distance\n",
    "from models import Perceptron, SVM, Softmax, Logistic\n",
    "from kaggle_submission import output_submission_csv\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the number of images for each split and load the images.\n",
    "<br /> \n",
    "TRAIN_IMAGES + VAL_IMAGES = (0, 60000]\n",
    ", TEST_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission we will use the default values \n",
    "TRAIN_IMAGES = 50000\n",
    "VAL_IMAGES = 10000\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n",
    "X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n",
    "X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n",
    "X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n",
    "n_class_fashion = len(np.unique(y_test_fashion))\n",
    "n_dimension_fashion = X_train_fashion.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  10911\n",
      "Number of val samples:  3637\n",
      "Number of test samples:  3637\n"
     ]
    }
   ],
   "source": [
    "# loads train / test / val splits of 80%, 20%, 20% \n",
    "data = get_RICE_data()\n",
    "X_train_RICE, y_train_RICE = data['X_train'], data['y_train']\n",
    "X_val_RICE, y_val_RICE = data['X_val'], data['y_val']\n",
    "X_test_RICE, y_test_RICE = data['X_test'], data['y_test']\n",
    "n_class_RICE = len(np.unique(y_test_RICE))\n",
    "\n",
    "print(\"Number of train samples: \", X_train_RICE.shape[0])\n",
    "print(\"Number of val samples: \", X_val_RICE.shape[0])\n",
    "print(\"Number of test samples: \", X_test_RICE.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test == pred) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Perceptron classifier in the **models/perceptron.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Perceptron classifier class \n",
    "- The train function of the Perceptron class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "\n",
    "percept_fashion = Perceptron(n_class_fashion, lr, n_epochs)\n",
    "percept_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/perceptron_submission_fashion.csv', percept_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "\n",
    "percept_RICE = Perceptron(n_class_RICE, lr, n_epochs)\n",
    "percept_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement a \"soft margin\" SVM. In this formulation you will maximize the margin between positive and negative training examples and penalize margin violations using a hinge loss.\n",
    "\n",
    "We will optimize the SVM loss using SGD. This means you must compute the loss function with respect to model weights. You will use this gradient to update the model weights.\n",
    "\n",
    "SVM optimized with SGD has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Epochs** - similar to as defined above in Perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case it is a coefficient on the term which maximizes the margin. You could try different values. The default value is set to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the SVM using SGD in the **models/svm.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the SVM classifier class \n",
    "- The train function of the SVM class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SVM.__init__() takes 5 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m reg_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 6\u001b[0m svm_fashion \u001b[38;5;241m=\u001b[39m \u001b[43mSVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_class_fashion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_dimension_fashion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_const\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m svm_fashion\u001b[38;5;241m.\u001b[39mtrain(X_train_fashion, y_train_fashion)\n",
      "\u001b[1;31mTypeError\u001b[0m: SVM.__init__() takes 5 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_fashion = SVM(n_class_fashion, lr, n_epochs, reg_const)\n",
    "svm_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/svm_submission_fashion.csv', svm_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_RICE = SVM(n_class_RICE, lr, n_epochs, reg_const)\n",
    "svm_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVM on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, you will train a Softmax classifier. This classifier consists of a linear function of the input data followed by a softmax function which outputs a vector of dimension C (number of classes) for each data point. Each entry of the softmax output vector corresponds to a confidence in one of the C classes, and like a probability distribution, the entries of the output vector sum to 1. We use a cross-entropy loss on this sotmax output to train the model. \n",
    "\n",
    "Check the following link as an additional resource on softmax classification: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "Once again we will train the classifier with SGD. This means you need to compute the gradients of the softmax cross-entropy loss function according to the weights and update the weights using this gradient. Check the following link to help with implementing the gradient updates: https://deepnotes.io/softmax-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax classifier has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - As above, this controls how much the model weights are updated with respect to their gradient.\n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case, we minimize the L2 norm of the model weights as regularization, so the regularization constant is a coefficient on the L2 norm in the combined cross-entropy and regularization objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement a softmax classifier using SGD in the **models/softmax.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Softmax classifier class \n",
    "- The train function of the Softmax class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 Accuracy: 55.05\n",
      "Epoch 101/1000 Accuracy: 81.46600000000001\n",
      "Epoch 201/1000 Accuracy: 83.074\n",
      "Epoch 301/1000 Accuracy: 83.59400000000001\n",
      "Epoch 401/1000 Accuracy: 84.06400000000001\n",
      "Epoch 501/1000 Accuracy: 84.234\n",
      "Epoch 601/1000 Accuracy: 84.478\n",
      "Epoch 701/1000 Accuracy: 84.804\n",
      "Epoch 801/1000 Accuracy: 85.004\n",
      "Epoch 901/1000 Accuracy: 85.006\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 2000\n",
    "reg_const = 0.1\n",
    "batch_size = 512\n",
    "\n",
    "softmax_fashion = Softmax(n_class_fashion, lr, batch_size, n_epochs, reg_const)\n",
    "softmax_fashion.train(X_train_fashion, y_train_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 85.074000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 84.200000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 83.160000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/softmax_submission_fashion.csv', softmax_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 Accuracy: 45.220419759875355\n",
      "Epoch 101/1000 Accuracy: 71.8907524516543\n",
      "Epoch 201/1000 Accuracy: 69.20538905691504\n",
      "Epoch 301/1000 Accuracy: 74.85106772981395\n",
      "Epoch 401/1000 Accuracy: 74.85106772981395\n",
      "Epoch 501/1000 Accuracy: 74.85106772981395\n",
      "Epoch 601/1000 Accuracy: 74.85106772981395\n",
      "Epoch 701/1000 Accuracy: 74.85106772981395\n",
      "Epoch 801/1000 Accuracy: 74.85106772981395\n",
      "Epoch 901/1000 Accuracy: 74.85106772981395\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "n_epochs = 1000\n",
    "reg_const = 0.05\n",
    "batch_size = 10911\n",
    "\n",
    "softmax_RICE = Softmax(n_class_RICE, lr, batch_size, n_epochs, reg_const)\n",
    "softmax_RICE.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 76.354138\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 77.069013\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 75.556778\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_RICE.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Threshold** - The decision boundary of the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Logistic Classifier in the **models/logistic.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\UIUC\\Spring 2023\\CS444 - Deep Learning for Computer Vision\\assignment1\\models\\logistic.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 Accuracy: 76.70241041151132\n",
      "Epoch 2/200 Accuracy: 76.9865273577124\n",
      "Epoch 3/200 Accuracy: 79.18614242507562\n",
      "Epoch 4/200 Accuracy: 78.66373384657685\n",
      "Epoch 5/200 Accuracy: 78.78287966272569\n",
      "Epoch 6/200 Accuracy: 65.57602419576574\n",
      "Epoch 7/200 Accuracy: 79.03033635780406\n",
      "Epoch 8/200 Accuracy: 77.94885894968381\n",
      "Epoch 9/200 Accuracy: 78.85620016497114\n",
      "Epoch 10/200 Accuracy: 79.25946292732105\n",
      "Epoch 11/200 Accuracy: 77.06901292273852\n",
      "Epoch 12/200 Accuracy: 79.24113280175969\n",
      "Epoch 13/200 Accuracy: 68.73797085510036\n",
      "Epoch 14/200 Accuracy: 79.13115204839153\n",
      "Epoch 15/200 Accuracy: 78.0405095774906\n",
      "Epoch 16/200 Accuracy: 78.60874346989277\n",
      "Epoch 17/200 Accuracy: 79.3786087434699\n",
      "Epoch 18/200 Accuracy: 76.7574007881954\n",
      "Epoch 19/200 Accuracy: 77.98551920080654\n",
      "Epoch 20/200 Accuracy: 78.41627715149849\n",
      "Epoch 21/200 Accuracy: 79.3786087434699\n",
      "Epoch 22/200 Accuracy: 77.49060581064981\n",
      "Epoch 23/200 Accuracy: 71.88158738887361\n",
      "Epoch 24/200 Accuracy: 78.31546146091101\n",
      "Epoch 25/200 Accuracy: 78.89286041609384\n",
      "Epoch 26/200 Accuracy: 78.84703510219046\n",
      "Epoch 27/200 Accuracy: 65.48437356795894\n",
      "Epoch 28/200 Accuracy: 79.02117129502338\n",
      "Epoch 29/200 Accuracy: 79.51608468518009\n",
      "Epoch 30/200 Accuracy: 71.97323801668041\n",
      "Epoch 31/200 Accuracy: 75.30015580606727\n",
      "Epoch 32/200 Accuracy: 78.37045183759508\n",
      "Epoch 33/200 Accuracy: 79.62606543854825\n",
      "Epoch 34/200 Accuracy: 76.87654660434424\n",
      "Epoch 35/200 Accuracy: 79.70855100357439\n",
      "Epoch 36/200 Accuracy: 69.42535056365135\n",
      "Epoch 37/200 Accuracy: 79.7452112546971\n",
      "Epoch 38/200 Accuracy: 79.21363761341766\n",
      "Epoch 39/200 Accuracy: 78.19631564476217\n",
      "Epoch 40/200 Accuracy: 79.76354138025845\n",
      "Epoch 41/200 Accuracy: 76.58326459536248\n",
      "Epoch 42/200 Accuracy: 79.8368618825039\n",
      "Epoch 43/200 Accuracy: 73.92539638896527\n",
      "Epoch 44/200 Accuracy: 78.24214095866556\n",
      "Epoch 45/200 Accuracy: 78.23297589588488\n",
      "Epoch 46/200 Accuracy: 78.79204472550637\n",
      "Epoch 47/200 Accuracy: 79.70855100357439\n",
      "Epoch 48/200 Accuracy: 77.80221794519292\n",
      "Epoch 49/200 Accuracy: 79.47942443405738\n",
      "Epoch 50/200 Accuracy: 78.52625790486665\n",
      "Epoch 51/200 Accuracy: 79.90101732196865\n",
      "Epoch 52/200 Accuracy: 74.33782421409587\n",
      "Epoch 53/200 Accuracy: 78.086334891394\n",
      "Epoch 54/200 Accuracy: 78.544588030428\n",
      "Epoch 55/200 Accuracy: 79.84602694528458\n",
      "Epoch 56/200 Accuracy: 75.62093300339107\n",
      "Epoch 57/200 Accuracy: 80.0659884520209\n",
      "Epoch 58/200 Accuracy: 75.85005957290808\n",
      "Epoch 59/200 Accuracy: 80.0201631381175\n",
      "Epoch 60/200 Accuracy: 78.4529374026212\n",
      "Epoch 61/200 Accuracy: 78.48043259096325\n",
      "Epoch 62/200 Accuracy: 78.58124828155073\n",
      "Epoch 63/200 Accuracy: 79.77270644303913\n",
      "Epoch 64/200 Accuracy: 75.0068737970855\n",
      "Epoch 65/200 Accuracy: 79.76354138025845\n",
      "Epoch 66/200 Accuracy: 78.89286041609384\n",
      "Epoch 67/200 Accuracy: 80.19429933095041\n",
      "Epoch 68/200 Accuracy: 78.52625790486665\n",
      "Epoch 69/200 Accuracy: 78.59041334433141\n",
      "Epoch 70/200 Accuracy: 78.41627715149849\n",
      "Epoch 71/200 Accuracy: 78.32462652369169\n",
      "Epoch 72/200 Accuracy: 79.16781229951425\n",
      "Epoch 73/200 Accuracy: 80.2492897076345\n",
      "Epoch 74/200 Accuracy: 74.54862065805152\n",
      "Epoch 75/200 Accuracy: 78.19631564476217\n",
      "Epoch 76/200 Accuracy: 78.67289890935753\n",
      "Epoch 77/200 Accuracy: 80.0659884520209\n",
      "Epoch 78/200 Accuracy: 71.10255705251582\n",
      "Epoch 79/200 Accuracy: 79.07616167170745\n",
      "Epoch 80/200 Accuracy: 80.13930895426634\n",
      "Epoch 81/200 Accuracy: 78.80120978828705\n",
      "Epoch 82/200 Accuracy: 78.7278892860416\n",
      "Epoch 83/200 Accuracy: 78.65456878379617\n",
      "Epoch 84/200 Accuracy: 78.74621941160297\n",
      "Epoch 85/200 Accuracy: 79.93767757309136\n",
      "Epoch 86/200 Accuracy: 78.59957840711209\n",
      "Epoch 87/200 Accuracy: 78.43460727705984\n",
      "Epoch 88/200 Accuracy: 78.75538447438365\n",
      "Epoch 89/200 Accuracy: 80.42342590046742\n",
      "Epoch 90/200 Accuracy: 74.6402712858583\n",
      "Epoch 91/200 Accuracy: 78.37961690037577\n",
      "Epoch 92/200 Accuracy: 78.66373384657685\n",
      "Epoch 93/200 Accuracy: 79.45192924571533\n",
      "Epoch 94/200 Accuracy: 80.54257171661627\n",
      "Epoch 95/200 Accuracy: 76.31747777472275\n",
      "Epoch 96/200 Accuracy: 80.53340665383558\n",
      "Epoch 97/200 Accuracy: 74.43863990468334\n",
      "Epoch 98/200 Accuracy: 78.31546146091101\n",
      "Epoch 99/200 Accuracy: 80.73503803501055\n",
      "Epoch 100/200 Accuracy: 76.33580790028411\n",
      "Epoch 101/200 Accuracy: 80.76253322335259\n",
      "Epoch 102/200 Accuracy: 76.19833195857392\n",
      "Epoch 103/200 Accuracy: 80.65255246998441\n",
      "Epoch 104/200 Accuracy: 78.24214095866556\n",
      "Epoch 105/200 Accuracy: 80.83585372559801\n",
      "Epoch 106/200 Accuracy: 79.75437631747778\n",
      "Epoch 107/200 Accuracy: 78.85620016497114\n",
      "Epoch 108/200 Accuracy: 78.9111905416552\n",
      "Epoch 109/200 Accuracy: 79.17697736229493\n",
      "Epoch 110/200 Accuracy: 80.80835853725597\n",
      "Epoch 111/200 Accuracy: 75.12601961323435\n",
      "Epoch 112/200 Accuracy: 78.42544221427917\n",
      "Epoch 113/200 Accuracy: 79.41526899459261\n",
      "Epoch 114/200 Accuracy: 80.85418385115938\n",
      "Epoch 115/200 Accuracy: 76.03336082852168\n",
      "Epoch 116/200 Accuracy: 80.19429933095041\n",
      "Epoch 117/200 Accuracy: 78.83787003940978\n",
      "Epoch 118/200 Accuracy: 78.76454953716433\n",
      "Epoch 119/200 Accuracy: 78.93868572999725\n",
      "Epoch 120/200 Accuracy: 79.26862799010173\n",
      "Epoch 121/200 Accuracy: 79.43359912015397\n",
      "Epoch 122/200 Accuracy: 80.92750435340483\n",
      "Epoch 123/200 Accuracy: 74.83273760425259\n",
      "Epoch 124/200 Accuracy: 78.63623865823482\n",
      "Epoch 125/200 Accuracy: 79.30528824122445\n",
      "Epoch 126/200 Accuracy: 79.0120062322427\n",
      "Epoch 127/200 Accuracy: 79.70855100357439\n",
      "Epoch 128/200 Accuracy: 81.05581523233434\n",
      "Epoch 129/200 Accuracy: 75.82256438456604\n",
      "Epoch 130/200 Accuracy: 80.8450187883787\n",
      "Epoch 131/200 Accuracy: 69.69113738429108\n",
      "Epoch 132/200 Accuracy: 72.55980203464394\n",
      "Epoch 133/200 Accuracy: 79.18614242507562\n",
      "Epoch 134/200 Accuracy: 79.0944917972688\n",
      "Epoch 135/200 Accuracy: 79.0944917972688\n",
      "Epoch 136/200 Accuracy: 79.1953074878563\n",
      "Epoch 137/200 Accuracy: 79.8368618825039\n",
      "Epoch 138/200 Accuracy: 81.27577673907066\n",
      "Epoch 139/200 Accuracy: 76.52827421867839\n",
      "Epoch 140/200 Accuracy: 80.2034643937311\n",
      "Epoch 141/200 Accuracy: 79.3786087434699\n",
      "Epoch 142/200 Accuracy: 79.20447255063698\n",
      "Epoch 143/200 Accuracy: 79.34194849234717\n",
      "Epoch 144/200 Accuracy: 79.87352213362662\n",
      "Epoch 145/200 Accuracy: 80.93666941618551\n",
      "Epoch 146/200 Accuracy: 67.66565850976079\n",
      "Epoch 147/200 Accuracy: 78.7278892860416\n",
      "Epoch 148/200 Accuracy: 81.42241774356155\n",
      "Epoch 149/200 Accuracy: 76.12501145632848\n",
      "Epoch 150/200 Accuracy: 79.18614242507562\n",
      "Epoch 151/200 Accuracy: 79.42443405737329\n",
      "Epoch 152/200 Accuracy: 79.20447255063698\n",
      "Epoch 153/200 Accuracy: 79.58940518742553\n",
      "Epoch 154/200 Accuracy: 79.22280267619833\n",
      "Epoch 155/200 Accuracy: 80.68004765832646\n",
      "Epoch 156/200 Accuracy: 78.60874346989277\n",
      "Epoch 157/200 Accuracy: 79.71771606635507\n",
      "Epoch 158/200 Accuracy: 80.79919347447529\n",
      "Epoch 159/200 Accuracy: 78.46210246540188\n",
      "Epoch 160/200 Accuracy: 81.61488406195583\n",
      "Epoch 161/200 Accuracy: 77.92136376134177\n",
      "Epoch 162/200 Accuracy: 80.90917422784347\n",
      "Epoch 163/200 Accuracy: 81.76152506644671\n",
      "Epoch 164/200 Accuracy: 81.13830079736046\n",
      "Epoch 165/200 Accuracy: 69.75529282375584\n",
      "Epoch 166/200 Accuracy: 73.73293007057097\n",
      "Epoch 167/200 Accuracy: 78.71872422326092\n",
      "Epoch 168/200 Accuracy: 81.43158280634223\n",
      "Epoch 169/200 Accuracy: 77.24314911557144\n",
      "Epoch 170/200 Accuracy: 81.73402987810466\n",
      "Epoch 171/200 Accuracy: 76.18916689579324\n",
      "Epoch 172/200 Accuracy: 81.3490972413161\n",
      "Epoch 173/200 Accuracy: 68.42635872055723\n",
      "Epoch 174/200 Accuracy: 76.2991476491614\n",
      "Epoch 175/200 Accuracy: 77.80221794519292\n",
      "Epoch 176/200 Accuracy: 81.14746586014114\n",
      "Epoch 177/200 Accuracy: 81.14746586014114\n",
      "Epoch 178/200 Accuracy: 81.82568050591146\n",
      "Epoch 179/200 Accuracy: 80.19429933095041\n",
      "Epoch 180/200 Accuracy: 79.32361836678581\n",
      "Epoch 181/200 Accuracy: 81.56905874805243\n",
      "Epoch 182/200 Accuracy: 74.29199890019247\n",
      "Epoch 183/200 Accuracy: 78.93868572999725\n",
      "Epoch 184/200 Accuracy: 81.3490972413161\n",
      "Epoch 185/200 Accuracy: 82.40307946109431\n",
      "Epoch 186/200 Accuracy: 81.3032719274127\n",
      "Epoch 187/200 Accuracy: 81.61488406195583\n",
      "Epoch 188/200 Accuracy: 65.87847126752818\n",
      "Epoch 189/200 Accuracy: 72.4864815323985\n",
      "Epoch 190/200 Accuracy: 81.37659242965815\n",
      "Epoch 191/200 Accuracy: 68.39886353221519\n",
      "Epoch 192/200 Accuracy: 81.74319494088535\n",
      "Epoch 193/200 Accuracy: 79.07616167170745\n",
      "Epoch 194/200 Accuracy: 81.3032719274127\n",
      "Epoch 195/200 Accuracy: 81.3490972413161\n",
      "Epoch 196/200 Accuracy: 77.82054807075428\n",
      "Epoch 197/200 Accuracy: 81.67903950142058\n",
      "Epoch 198/200 Accuracy: 68.78379616900375\n",
      "Epoch 199/200 Accuracy: 82.11896251489323\n",
      "Epoch 200/200 Accuracy: 76.85821647878288\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "n_epochs = 200\n",
    "threshold = 0.5\n",
    "batch_size = 1024\n",
    "reg_const = 0.05\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs, threshold, batch_size, reg_const)\n",
    "lr.train(X_train_RICE, y_train_RICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 76.858216\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_RICE)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 76.106681\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_val_RICE)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_RICE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 76.766566\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_test_RICE)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_RICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
